{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid/Test sizes: 319 107 143\n",
      "Validation Accuracy: 0.94 [Classifier 1]\n",
      "Validation Accuracy: 0.95 [Classifier 2]\n",
      "Validation Accuracy: 0.95 [Classifier 3]\n",
      "Validation Accuracy: 0.95 [Ensemble]\n",
      "Test Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "print('Train/Valid/Test sizes:', y_train.shape[0], y_val.shape[0], y_test.shape[0])\n",
    "\n",
    "clf1 = DecisionTreeClassifier(random_state=42, max_depth=1)\n",
    "clf2 = DecisionTreeClassifier(random_state=42, max_depth=2)\n",
    "clf3 = DecisionTreeClassifier(random_state=42, max_depth=3)\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[1, 1, 1])\n",
    "\n",
    "labels = ['Classifier 1', 'Classifier 2', 'Classifier 3', 'Ensemble']\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], labels):\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Validation Accuracy: %0.2f [%s]\" % (clf.score(X_val, y_val), label))\n",
    "    \n",
    "print(\"Test Accuracy: %0.2f\" % eclf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Accuracy: 0.95\n",
      "Test Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy',\n",
    "                              random_state=42,\n",
    "                              max_depth=None)\n",
    "\n",
    "\n",
    "bag = BaggingClassifier(estimator=tree,\n",
    "                        n_estimators=500,\n",
    "                        oob_score=True,\n",
    "                        bootstrap=True,\n",
    "                        bootstrap_features=False,\n",
    "                        n_jobs=-1, ## -1 usa todos los procesadores (Tareas en paralelo)\n",
    "                        random_state=42)\n",
    "\n",
    "bag.fit(X_train, y_train)\n",
    "    \n",
    "print(\"OOB Accuracy: %0.2f\" % bag.oob_score_)\n",
    "print(\"Test Accuracy: %0.2f\" % bag.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basicamente estos algoritmos (Bootstrap agregating, adaboost, hacen varias bolsas de datos del training set, de distintas maneras)\n",
    "\n",
    "Adaboost va mejorando cada bolsa con los elementos mal clasificados en la anterior, luego hace una votacion mayoritaria con los modelos de cada bolsa o simplemente usa la bolsa que mejor se adapto(No estoy seguro pero quizas sea la ultima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Por que si aumento el max_depth a 10 baja el accuracy? overfitting?\n",
    "tree = DecisionTreeClassifier(criterion='entropy',\n",
    "                              random_state=42,\n",
    "                              max_depth=1)\n",
    "\n",
    "\n",
    "boost = AdaBoostClassifier(estimator=tree,\n",
    "                           n_estimators=500,\n",
    "                           algorithm='SAMME',\n",
    "                           random_state=42)\n",
    "\n",
    "boost.fit(X_train, y_train)\n",
    "    \n",
    "print(\"Test Accuracy: %0.2f\" % boost.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "boost = GradientBoostingClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    random_state=1)\n",
    "\n",
    "boost.fit(X_train, y_train)\n",
    "    \n",
    "print(\"Test Accuracy: %0.2f\" % boost.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=100,\n",
    "                                max_depth=None,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_samples_split=2,\n",
    "                                max_features=0.3,\n",
    "                                random_state=42)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "    \n",
    "print(\"Test Accuracy: %0.2f\" % forest.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
